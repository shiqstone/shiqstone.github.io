[{"title":"一次慢查询问题的排查","url":"/2020/02/01/troubleshooting-a-slow-query/","content":"\n## 问题发现\n某个业务的查询页面打开非常慢，甚至卡死，通过排查日志，定位到是分页查询有慢查询sql，其中一条简单查询耗时长达40多秒\n结合前后其他sql耗时都在毫秒级，排除网络问题，在命令行中执行sql也同样很慢\n\n## 问题分析\n有问题的sql如下\n```sql\nmysql> select count(*) from test_tab where update_time>='2020-01-10' and update_time<'2020-01-11' and label is not null;\n+----------+\n| count(*) |\n+----------+\n|   229330 |\n+----------+\n1 row in set (41.34 sec)\n```\n\n首先看了一下全表数据，接近千万级，但是有趣的是耗时只有不到4s，对于千万级的表，勉强可以接收\n```sql\nmysql> select count(*) from test_tab;\n+----------+\n| count(*) |\n+----------+\n|  9469766 |\n+----------+\n1 row in set (3.86 sec)\n```\n\n更有意思的是，执行相同条件查询数据记录的sql，结果10ms就返回了\n```sql\nmysql> select id, label, call_round, dial_start_time, dial_duration, disconnect_reason, update_time from test_tab where update_time>='2020-01-10' and update_time<'2020-01-11' and label is not null order by update_time desc limit 0, 20;\n+----------+-------+------------+---------------------+---------------+-------------------+---------------------+\n| id       | label | call_round | dial_start_time     | dial_duration | disconnect_reason | update_time         |\n+----------+-------+------------+---------------------+---------------+-------------------+---------------------+\n| 17510408 | F     |          0 | NULL                |          NULL | NULL              | 2020-01-10 21:01:09 |\n| 17510411 | F     |          0 | NULL                |          NULL | NULL              | 2020-01-10 21:01:08 |\n| 17510421 | E     |          8 | 2020-01-10 20:59:43 |            78 | NULL              | 2020-01-10 21:00:58 |\n| 17510418 | F     |          0 | NULL                |          NULL | NULL              | 2020-01-10 21:00:54 |\n| 17510407 | C     |         15 | 2020-01-10 20:59:33 |            78 | NULL              | 2020-01-10 21:00:48 |\n| 17510416 | A     |          8 | 2020-01-10 20:59:34 |            57 | NULL              | 2020-01-10 21:00:28 |\n| 17510413 | C     |          2 | 2020-01-10 21:00:04 |            20 | NULL              | 2020-01-10 21:00:21 |\n| 17510415 | F     |       NULL | NULL                |          NULL | NULL              | 2020-01-10 21:00:20 |\n| 17510412 | F     |       NULL | NULL                |          NULL | NULL              | 2020-01-10 21:00:18 |\n| 17510423 | C     |          4 | 2020-01-10 20:59:49 |            31 | NULL              | 2020-01-10 21:00:17 |\n| 17510420 | C     |          1 | 2020-01-10 20:59:46 |             4 | NULL              | 2020-01-10 20:59:47 |\n| 17510424 | F     |       NULL | NULL                |          NULL | 1                 | 2020-01-10 20:59:44 |\n| 17510410 | F     |       NULL | NULL                |          NULL | 1                 | 2020-01-10 20:59:41 |\n| 17510419 | F     |       NULL | NULL                |          NULL | 1                 | 2020-01-10 20:59:38 |\n| 17510437 | F     |          0 | NULL                |          NULL | NULL              | 2020-01-10 20:59:37 |\n| 17510441 | F     |          0 | NULL                |          NULL | NULL              | 2020-01-10 20:59:35 |\n| 17510417 | F     |       NULL | NULL                |          NULL | 1                 | 2020-01-10 20:59:34 |\n| 17510414 | F     |       NULL | NULL                |          NULL | 1                 | 2020-01-10 20:59:32 |\n| 17510409 | F     |       NULL | NULL                |          NULL | 8                 | 2020-01-10 20:59:31 |\n| 17510422 | F     |       NULL | NULL                |          NULL | 6                 | 2020-01-10 20:59:29 |\n+----------+-------+------------+---------------------+---------------+-------------------+---------------------+\n20 rows in set (0.01 sec)\n```\n\n分别查看各条sql的执行计划，结果如下\nsql_1:\n```sql\nmysql> explain select count(*) from test_tab;\n+----+-------------+---------------------------+-------+---------------+-------------------------------+---------+------+----------+-------------+\n| id | select_type | table                     | type  | possible_keys | key                           | key_len | ref  | rows     | Extra       |\n+----+-------------+---------------------------+-------+---------------+-------------------------------+---------+------+----------+-------------+\n|  1 | SIMPLE      | test_tab | index | NULL          | ai_dianxiao_update_time_index | 4       | NULL | 11823805 | Using index |\n+----+-------------+---------------------------+-------+---------------+-------------------------------+---------+------+----------+-------------+\n```\nsql_2:\n```sql\nmysql> explain select count(*) from test_tab where update_time>='2020-01-10' and update_time<'2020-01-11' and label is not null;\n+----+-------------+---------------------------+-------+-------------------------------+-------------------------------+---------+------+--------+------------------------------------+\n| id | select_type | table                     | type  | possible_keys                 | key                           | key_len | ref  | rows   | Extra                              |\n+----+-------------+---------------------------+-------+-------------------------------+-------------------------------+---------+------+--------+------------------------------------+\n|  1 | SIMPLE      | test_tab | range | ai_dianxiao_update_time_index | ai_dianxiao_update_time_index | 4       | NULL | 515618 | Using index condition; Using where |\n+----+-------------+---------------------------+-------+-------------------------------+-------------------------------+---------+------+--------+------------------------------------+\n```\nsql_3:\n```sql\nmysql> explain select id, label, call_round, dial_start_time, dial_duration, disconnect_reason, update_time from test_tab where update_time>='2020-01-10' and update_time<'2020-01-11' and label is not null order by update_time desc limit 0, 20;\n+----+-------------+---------------------------+-------+-------------------------------+-------------------------------+---------+------+--------+------------------------------------+\n| id | select_type | table                     | type  | possible_keys                 | key                           | key_len | ref  | rows   | Extra                              |\n+----+-------------+---------------------------+-------+-------------------------------+-------------------------------+---------+------+--------+------------------------------------+\n|  1 | SIMPLE      | test_tab | range | ai_dianxiao_update_time_index | ai_dianxiao_update_time_index | 4       | NULL | 515618 | Using index condition; Using where |\n+----+-------------+---------------------------+-------+-------------------------------+-------------------------------+---------+------+--------+------------------------------------+\n```\n初步分析三个sql都用到了索引，sql_1虽然是查询全表数据，但是直接命中二级索引，所以查询速度也很快[4]\n通过比较执行计划可以看到，sql_2和sql_3完全一致但是执行速度相差巨大，推测sql_3是因为筛选结果集靠前的结果，且只取结果集20条，所以很快返回结果\n\nsql_4:\n```sql\nmysql> select id, label, call_round, dial_start_time, dial_duration, disconnect_reason, update_time from test_tab where update_time>='2020-01-10' and update_time<'2020-01-11' and label is not null order by update_time desc limit 50000, 20;\n+----------+-------+------------+---------------------+---------------+-----------------------+---------------------+\n| id       | label | call_round | dial_start_time     | dial_duration | disconnect_reason     | update_time         |\n+----------+-------+------------+---------------------+---------------+-----------------------+---------------------+\n| 17415457 | F     |       NULL | NULL                |          NULL | 1                     | 2020-01-10 14:06:24 |\n| 17415445 | F     |       NULL | NULL                |          NULL | 1                     | 2020-01-10 14:06:24 |\n| 17456511 | F     |       NULL | NULL                |          NULL | -ERR NO_USER_RESPONSE | 2020-01-10 14:06:23 |\n| 17456500 | F     |       NULL | NULL                |          NULL | 1                     | 2020-01-10 14:06:23 |\n| 17456491 | F     |       NULL | NULL                |          NULL | 1                     | 2020-01-10 14:06:23 |\n| 17456428 | G     |          0 | 2020-01-10 14:06:14 |            10 | NULL                  | 2020-01-10 14:06:23 |\n| 17433875 | F     |       NULL | NULL                |          NULL | NULL                  | 2020-01-10 14:06:23 |\n| 17433874 | F     |       NULL | NULL                |          NULL | NULL                  | 2020-01-10 14:06:23 |\n| 17415635 | F     |       NULL | 2020-01-10 14:02:37 |          NULL | 2                     | 2020-01-10 14:06:23 |\n| 17456501 | F     |       NULL | NULL                |          NULL | 5                     | 2020-01-10 14:06:22 |\n| 17456483 | F     |       NULL | NULL                |          NULL | 1                     | 2020-01-10 14:06:22 |\n| 17456460 | G     |          0 | 2020-01-10 14:06:17 |             7 | NULL                  | 2020-01-10 14:06:22 |\n| 17456444 | G     |          0 | 2020-01-10 14:06:15 |             9 | NULL                  | 2020-01-10 14:06:22 |\n| 17456496 | F     |       NULL | NULL                |          NULL | 6                     | 2020-01-10 14:06:21 |\n| 17456495 | F     |       NULL | NULL                |          NULL | 1                     | 2020-01-10 14:06:21 |\n| 17456464 | G     |          0 | 2020-01-10 14:06:15 |             7 | NULL                  | 2020-01-10 14:06:21 |\n| 17415461 | F     |       NULL | NULL                |          NULL | 4                     | 2020-01-10 14:06:21 |\n| 17456477 | F     |       NULL | NULL                |          NULL | 1                     | 2020-01-10 14:06:20 |\n| 17456474 | F     |       NULL | NULL                |          NULL | 1                     | 2020-01-10 14:06:20 |\n| 17456462 | G     |          0 | 2020-01-10 14:06:08 |            14 | NULL                  | 2020-01-10 14:06:20 |\n+----------+-------+------------+---------------------+---------------+-----------------------+---------------------+\n20 rows in set (13.77 sec)\n```\n尝试执行sql_4，验证了这个推测，当筛选结果比较靠后时，游标定位比较耗时，结果返回就比较慢了，这种情况下，需要用其他一些方式来优化[5]，在此不展开\n\n再回到sql_2，通过各种尝试比较暂时排除索引问题，注意到这个业务的时间字段使用的是timestamp，猜测字段的数据类型会有影响\n为了不影响线上服务，先找了一个其他数据库，单表1200w数据，时间字段使用的是datetime，执行类似条件查询，居然不到一秒就返回结果，\n为了验证结果，在非服务时间，将线上表复制到测试数据库，修改字段类型为datetime，执行sql_2同样是秒级响应，满足要求\n\n根据检索网上资料[3]，对于InnoDB引擎，建立索引的情况下，datetime明显优于timestamp\n\n## 解决方案\n建议业务方修改数据表字段为datetime，可以根本解决问题\n但是业务方考虑之前是希望使用\"ON UPDATE CURRENT_TIMESTAMP\"特性而采用的timestamp，需要修改代码较多，暂时不愿调整，于是在这个案例中只能迁移历史数据，减少当前热表总记录的方式。\n\n另外，在分析过程中，还尝试修改查询条件，查询排序较靠前的记录，类似分页查询问题，速度有一定提升，分析是在索引进行扫描时，会预先根据条件按排序进行筛选，这样排序靠前的结果能更快的返回，查询速度自然要优于结果靠后的查询\n```sql\nmysql> select count(*) from test_tab where update_time>='2019-12-01' and update_time<'2019-12-02' and label is not null;\n+----------+\n| count(*) |\n+----------+\n|    47302 |\n+----------+\n1 row in set (7.13 sec)\n```\n\n## 后记\n对于这次案例，也许这并不是唯一的解决方案，也不是最好的处理方式，但是在项目使用中，对比datetime和timestamp两个类型，个人还是比较倾向与使用前者，毕竟日常数据库引擎都是InnoDB\n也许使用timestamp唯一的优势只是使用\"ON UPDATE CURRENT_TIMESTAMP\"特性而少写一行更新时间代码而已，而且2038年也不远了\n另外，在排查过程中，也有人提出分区表的方案，一方面，对应分区表了解不够全面，对于mysql执行过程不可控，再则分区表的分区键设计不够灵活，最终没有采用\n\n## 参考\n[1]https://juejin.im/post/5bcc2935f265da0ac66987c9\n[2]https://www.cnblogs.com/kerrycode/p/9909093.html\n[3]https://blog.csdn.net/adsadadaddadasda/article/details/78933784\n[4]https://blog.csdn.net/wgw335363240/article/details/6295906\n[5]https://segmentfault.com/a/1190000008859706\n[6]http://hedengcheng.com/?p=577\n[7]https://www.w3cschool.cn/architectroad/architectroad-mysql-partition-table.html"},{"title":"尝试使用Go截取视频生成缩略图","url":"/2020/01/31/try-golang-snapshot-video-thumb/","content":"\n### 1 基本命令\n使用ffmpeg截取视频生成图片，原始命令为\n```bash\nffmpeg -i src.mp4 -y -f mjpeg -ss 3 -t 1 -s 80x44 dist.jpg\n```\n### 2 简单封装\n```go\npackage main\n                    \nimport (\n  \"bytes\"       \n  \"fmt\"\n  \"os/exec\"     \n)\nfunc main() {     \n  filename := \"test.mp4\"\n  width := 288  \n  height := 512 \n  output := \"output.jpg\"   \n  cmd := exec.Command(\"ffmpeg\", \"-i\", filename, \"-vframes\", \"1\", \"-s\", fmt.Sprintf(\"%dx%d\", width, height), \"-f\", \"singlejpeg\", output)\n  var buffer bytes.Buffer\n  cmd.Stdout = &buffer \n  if cmd.Run() != nil {\n      panic(\"could not generate frame\")\n  }\n\n}\n```\n### 3 查询数据库\n增加从mysql数据库读取视频路径\n```go\npackage main\n  \nimport (\n    \"bytes\"\n    \"fmt\"\n    \"path\"\n    \"path/filepath\"\n    \"strings\"\n    \"os/exec\"\n    \"database/sql\"\n    _ \"github.com/go-sql-driver/mysql\"\n)\nfunc main() {\n    //user:password@tcp(localhost:5555)/dbname?charset=utf8\n    db, err := sql.Open(\"mysql\", \"root@tcp(localhost:3306)/dsp?charset=utf8\")\n    checkErr(err)\n\n    //查询数据\n    rows, err := db.Query(\"SELECT video_s3_url FROM material_video\")\n    checkErr(err)\n\n    for rows.Next() {\n        var video_s3_url string\n        err = rows.Scan(&video_s3_url)\n        checkErr(err)\n\n        fullpath := video_s3_url\n        //width := 288\n        //height := 512\n        fileName := filepath.Base(fullpath)\n        fileSuffix := path.Ext(fileName)\n        output := strings.TrimSuffix(fileName, fileSuffix) + \".png\" \n        //fmt.Println(output)\n        cmd := exec.Command(\"ffmpeg\", \"-i\", fullpath, \"-vframes\", \"1\", \"-ss\", \"3\", \"-t\", \"1\", output)\n        var buffer bytes.Buffer\n        cmd.Stdout = &buffer\n        if cmd.Run() != nil {\n            panic(\"could not generate frame\")\n        }\n        //break;\n    }\n}\n\nfunc checkErr(err error) {\n    if err != nil {\n        panic(err)\n    }\n}\n```\n### 4 更新数据库\n将生成图片路径更新到数据库\n```go\npackage main\n\nimport (\n    \"bytes\"\n    \"fmt\"\n    \"path\"\n    \"path/filepath\"\n    \"strings\"\n    \"os/exec\"\n    \"database/sql\"\n    _ \"github.com/go-sql-driver/mysql\"\n)\nfunc main() {\n    //user:password@tcp(localhost:5555)/dbname?charset=utf8\n    db, err := sql.Open(\"mysql\", \"root@tcp(localhost:3306)/dsp?charset=utf8\")\n    checkErr(err)\n\n    //查询数据\n    rows, err := db.Query(\"SELECT id, video_s3_url FROM material_video\")\n    checkErr(err)\n\n    cnt := 0\n    for rows.Next() {\n        var id int\n        var video_s3_url string\n        err = rows.Scan(&id, &video_s3_url)\n        checkErr(err)\n\n        fullpath := video_s3_url\n        fileName := filepath.Base(fullpath)\n        fileSuffix := path.Ext(fileName)\n        output := strings.TrimSuffix(fileName, fileSuffix) + \".png\" \n        cmd := exec.Command(\"ffmpeg\", \"-i\", fullpath, \"-vframes\", \"1\", \"-ss\", \"3\", \"-t\", \"1\", output)\n        var buffer bytes.Buffer\n        cmd.Stdout = &buffer\n        if cmd.Run() != nil {\n            panic(\"could not generate frame\")\n        }\n\n        //更新数据\n        stmt, err := db.Prepare(\"update material_video set video_thumb_url=? where id=?\")\n        checkErr(err)\n        res, err := stmt.Exec(output, id)\n        checkErr(err)\n        affect, err := res.RowsAffected()\n        checkErr(err)\n\n        if(affect>0) {\n            cnt++\n        }\n    }\n    fmt.Println(cnt)\n}\n\nfunc checkErr(err error) {\n    if err != nil {\n        panic(err)\n    }\n}\n```\n### 5 文件上传共享\n考虑本地存储文件的局限性，改为将生成文件上传到S3服务器上，便于后续共享访问\n```go\npackage main\n\nimport (\n    \"bytes\"\n    \"fmt\"\n    \"path\"\n    \"path/filepath\"\n    \"strings\"\n    \"os\"\n    \"os/exec\"\n    \"database/sql\"\n    _ \"github.com/go-sql-driver/mysql\"\n\n    \"net/http\"\n    \"github.com/aws/aws-sdk-go/aws\"\n    \"github.com/aws/aws-sdk-go/aws/credentials\"\n    \"github.com/aws/aws-sdk-go/aws/session\"\n    \"github.com/aws/aws-sdk-go/service/s3\"\n)\nfunc main() {\n    //user:password@tcp(localhost:5555)/dbname?charset=utf8\n    db, err := sql.Open(\"mysql\", \"root@tcp(localhost:3306)/dsp?charset=utf8\")\n    checkErr(err)\n\n    //query date\n    rows, err := db.Query(\"SELECT id, video_s3_url FROM material_video where video_thumb_url is null\")\n    checkErr(err)\n\n    access_key := \"access_key_str\"\n    secret_key := \"secret_key_str\"\n    end_point := \"http://test.s3.amazon.cn\"\n    bucket := \"bucket_str\" \n    // Configure to use S3 Server\n    s, err := session.NewSession(&aws.Config{\n        Region: aws.String(\"us-west-2\"),\n        Credentials: credentials.NewStaticCredentials( access_key, secret_key, \"\"),  // token can be left blank for now\n        Endpoint:         aws.String(end_point),\n        DisableSSL:       aws.Bool(true),\n        S3ForcePathStyle: aws.Bool(true),\n    })\n    if err != nil {\n        checkErr(err)\n    }\n\n    cnt := 0\n    for rows.Next() {\n        var id int\n        var video_s3_url string\n        err = rows.Scan(&id, &video_s3_url)\n        checkErr(err)\n\n        fullpath := video_s3_url\n        fileName := filepath.Base(fullpath)\n        fileSuffix := path.Ext(fileName)\n        fileSingleName := strings.TrimSuffix(fileName, fileSuffix)\n        output := fileSingleName + \".png\" \n        fmt.Println(output)\n\n        //delete exist file\n        err = os.Remove(output);\n        if err != nil {\n            fmt.Println(err);\n        }\n\n        fmt.Println(\"ffmpeg\", \"-i\", fullpath, \"-vframes\", \"1\", \"-ss\", \"3\", \"-t\", \"1\", output)\n        cmd := exec.Command(\"ffmpeg\", \"-i\", fullpath, \"-vframes\", \"1\", \"-ss\", \"3\", \"-t\", \"1\", output)\n        var buffer bytes.Buffer\n        cmd.Stdout = &buffer\n        if cmd.Run() != nil {\n            panic(\"could not generate frame\")\n        }\n\n        // Upload\n        err = AddFileToS3(s, bucket, output)\n        if err != nil {\n            checkErr(err)\n        }\n\n        thumb_url := end_point + \"/\" + bucket + \"/\" + output\n\n        //update db\n        stmt, err := db.Prepare(\"update material_video set video_thumb_url=? where id=?\")\n        checkErr(err)\n        res, err := stmt.Exec(thumb_url, id)\n        checkErr(err)\n        affect, err := res.RowsAffected()\n        checkErr(err)\n\n        if(affect>0) {\n            cnt++\n        }\n\n        if(cnt>10) {\n            break;\n        }\n    }\n    fmt.Println(cnt)\n}\n\nfunc checkErr(err error) {\n    if err != nil {\n        panic(err)\n    }\n}\n\nfunc AddFileToS3(s *session.Session, bucket string, fileDir string) error {\n\n    // Open the file for use\n    file, err := os.Open(fileDir)\n    if err != nil {\n        return err\n    }\n    defer file.Close()\n\n    // Get file size and read the file content into a buffer\n    fileInfo, _ := file.Stat()\n    var size int64 = fileInfo.Size()\n    buffer := make([]byte, size)\n    file.Read(buffer)\n\n    // Config settings: this is where you choose the bucket, filename, content-type etc.\n    // of the file you're uploading.\n    _, err = s3.New(s).PutObject(&s3.PutObjectInput{\n        Bucket:               aws.String(bucket),\n        Key:                  aws.String(fileDir),\n        //ACL:                  aws.String(\"private\"),\n        Body:                 bytes.NewReader(buffer),\n        ContentLength:        aws.Int64(size),\n        ContentType:          aws.String(http.DetectContentType(buffer)),\n        ContentDisposition:   aws.String(\"attachment\"),\n        ServerSideEncryption: aws.String(\"AES256\"),\n    })\n    return err\n}\n```\n\n### 6 敏感信息配置\n基本功能实现了，但是直接把数据库账号密码等配置的信息写在代码里的方式不够好，改为把数据库和S3配置使用配置文件方式\nconf/conf.yaml\n```yaml\ndb:\n    dialect : mysql\n    user : root\n    password :\n    host : localhost\n    port : 3306\n    database : dsp\n    charset : utf8\ns3:\n    access_key : access_key_str\n    secret_key : secret_key_str\n    end_point : http://test.s3.amazon.cn\n    bucket : bucket_str\n```\n\nsnapshot.go\n```go\npackage main\n\nimport (\n    \"io/ioutil\"\n    yaml \"gopkg.in/yaml.v2\"\n    \"bytes\"\n    //\"fmt\"\n    \"log\"\n    \"path\"\n    \"path/filepath\"\n    \"strings\"\n    \"os\"\n    \"os/exec\"\n    \"database/sql\"\n    _ \"github.com/go-sql-driver/mysql\"\n    \"time\"\n\n    \"net/http\"\n    \"github.com/aws/aws-sdk-go/aws\"\n    \"github.com/aws/aws-sdk-go/aws/credentials\"\n    \"github.com/aws/aws-sdk-go/aws/session\"\n    \"github.com/aws/aws-sdk-go/service/s3\"\n)\n\nvar db *sql.DB\nvar s *session.Session\n\nfunc main() {\n    var (\n        Config Config\n    )\n    data, err := ioutil.ReadFile(\"conf/conf.yaml\")\n    if err != nil {\n        checkErr(err)\n    }\n    err = yaml.Unmarshal(data, &Config)\n    if err != nil {\n        checkErr(err)\n    }\n\n    //user:password@tcp(localhost:5555)/dbname?charset=utf8\n    db, err = sql.Open(Config.Db.Dialect, Config.Db.User + \"@tcp(\" + Config.Db.Host + \":\" + Config.Db.Port + \")/\" + Config.Db.Database + \"?charset=\" + Config.Db.Charset)\n    checkErr(err)\n\n    //query date\n    rows, err := db.Query(\"SELECT id, video_s3_url FROM material_video where video_thumb_url is null\")\n    checkErr(err)\n\n    access_key := Config.S3.AccessKey\n    secret_key := Config.S3.SecretKey\n    end_point := Config.S3.EndPoint\n    bucket := Config.S3.Bucket\n    // Configure to use S3 Server\n    s, err = session.NewSession(&aws.Config{\n        Region: aws.String(\"us-west-2\"),\n        Credentials: credentials.NewStaticCredentials( access_key, secret_key, \"\"),  // token can be left blank for now\n        Endpoint:         aws.String(end_point),\n        DisableSSL:       aws.Bool(true),\n        S3ForcePathStyle: aws.Bool(true),\n    })\n    if err != nil {\n        checkErr(err)\n    }\n\n    cnt := 0\n    for rows.Next() {\n        var id int\n        var video_s3_url string\n        err = rows.Scan(&id, &video_s3_url)\n        checkErr(err)\n         process(id, video_s3_url, bucket, end_point)\n\n        if(cnt>10) {\n            break\n        }\n        cnt++\n    }\n    log.Println(cnt)\n}\n\nfunc process(id int, video_s3_url string, bucket string, end_point string) int64 {\n    fullpath := video_s3_url\n    fileName := filepath.Base(fullpath)\n    fileSuffix := path.Ext(fileName)\n    fileSingleName := strings.TrimSuffix(fileName, fileSuffix)\n    output := fileSingleName + \".png\" \n    log.Println(output)\n\n    //delete exist file\n    _ = os.Remove(output);\n\n    log.Println(\"ffmpeg\", \"-i\", fullpath, \"-vframes\", \"1\", \"-ss\", \"3\", \"-t\", \"1\", output)\n    cmd := exec.Command(\"ffmpeg\", \"-i\", fullpath, \"-vframes\", \"1\", \"-ss\", \"3\", \"-t\", \"1\", output)\n    var buffer bytes.Buffer\n    cmd.Stdout = &buffer\n    if cmd.Run() != nil {\n        //panic(\"could not generate frame\")\n        log.Println(\"could not generate frame\")\n    }\n\n    // Upload\n    err := AddFileToS3(bucket, output)\n    if err != nil {\n        log.Println(\"could not update to s3\")\n        checkErr(err)\n    }\n    log.Println(output, \"update to s3\")\n\n    thumb_url := end_point + \"/\" + bucket + \"/\" + output\n\n    //update db\n    timeStr := time.Now().Format(\"2006-01-02 15:04:05\")\n    log.Println(\"update material_video set video_thumb_url='\", thumb_url, \"', update_time='\", timeStr, \"' where id=\", id)\n    stmt, err := db.Prepare(\"update material_video set video_thumb_url=?, update_time=? where id=?\")\n    defer stmt.Close()\n    checkErr(err)\n    res, err := stmt.Exec(thumb_url, timeStr, id)\n    log.Println(\"res\", res)\n    checkErr(err)\n    affect, err := res.RowsAffected()\n    checkErr(err)\n    return affect\n}\n\nfunc checkErr(err error) {\n    log.Println(err)\n    if err != nil {\n        panic(err)\n    }\n}\n\nfunc AddFileToS3(bucket string, fileDir string) error {\n\n    // Open the file for use\n    file, err := os.Open(fileDir)\n    if err != nil {\n        return err\n    }\n    defer file.Close()\n\n    // Get file size and read the file content into a buffer\n    fileInfo, _ := file.Stat()\n    var size int64 = fileInfo.Size()\n    buffer := make([]byte, size)\n    file.Read(buffer)\n\n    // Config settings: this is where you choose the bucket, filename, content-type etc.\n    // of the file you're uploading.\n    _, err = s3.New(s).PutObject(&s3.PutObjectInput{\n        Bucket:               aws.String(bucket),\n        Key:                  aws.String(fileDir),\n        //ACL:                  aws.String(\"private\"),\n        Body:                 bytes.NewReader(buffer),\n        ContentLength:        aws.Int64(size),\n        ContentType:          aws.String(http.DetectContentType(buffer)),\n        ContentDisposition:   aws.String(\"attachment\"),\n        ServerSideEncryption: aws.String(\"AES256\"),\n    })\n    return err\n}\n\ntype Config struct {\n    Db DBConfigInfo\n    S3 S3ConfigInfo\n}\n\ntype DBConfigInfo struct {\n    Dialect  string `yaml:\"dialect\"`\n    User     string `yaml:\"user\"`\n    Password string `yaml:\"password\"`\n    Host     string `yaml:\"host\"`\n    Port     string `yaml:\"port\"`\n    Database string `yaml:\"database\"`\n    Charset  string `yaml:\"charset\"`\n}\n\ntype S3ConfigInfo struct {\n    AccessKey     string `yaml:\"access_key\"`\n    SecretKey     string `yaml:\"secret_key\"`\n    EndPoint      string `yaml:\"end_point\"`\n    Bucket        string `yaml:\"bucket\"`\n}\n```\n\n### 7 重构为并行处理\n单条处理耗时较久，尝试使用goroutine重构，提升性能\nsnapshot.go\n```go\npackage main\n\nimport (\n    \"io/ioutil\"\n    yaml \"gopkg.in/yaml.v2\"\n    \"bytes\"\n    //\"fmt\"\n    \"log\"\n    \"path\"\n    \"path/filepath\"\n    \"strings\"\n    \"os\"\n    \"os/exec\"\n    \"database/sql\"\n    _ \"github.com/go-sql-driver/mysql\"\n    \"time\"\n\n    \"net/http\"\n    \"github.com/aws/aws-sdk-go/aws\"\n    \"github.com/aws/aws-sdk-go/aws/credentials\"\n    \"github.com/aws/aws-sdk-go/aws/session\"\n    \"github.com/aws/aws-sdk-go/service/s3\"\n)\n\nvar db *sql.DB\nvar s *session.Session\nvar quit = make(chan int64, 100)\n\nfunc main() {\n    var (\n        Config Config\n    )\n    data, err := ioutil.ReadFile(\"conf/conf.yaml\")\n    if err != nil {\n        checkErr(err)\n    }\n    err = yaml.Unmarshal(data, &Config)\n    if err != nil {\n        checkErr(err)\n    }\n\n    //user:password@tcp(localhost:5555)/dbname?charset=utf8\n    db, err = sql.Open(Config.Db.Dialect, Config.Db.User + \"@tcp(\" + Config.Db.Host + \":\" + Config.Db.Port + \")/\" + Config.Db.Database + \"?charset=\" + Config.Db.Charset)\n    checkErr(err)\n\n    //query date\n    rows, err := db.Query(\"SELECT id, video_s3_url FROM material_video where video_thumb_url is null\")\n    checkErr(err)\n\n    access_key := Config.S3.AccessKey\n    secret_key := Config.S3.SecretKey\n    end_point := Config.S3.EndPoint\n    bucket := Config.S3.Bucket\n    // Configure to use S3 Server\n    s, err = session.NewSession(&aws.Config{\n        Region: aws.String(\"us-west-2\"),\n        Credentials: credentials.NewStaticCredentials( access_key, secret_key, \"\"),  // token can be left blank for now\n        Endpoint:         aws.String(end_point),\n        DisableSSL:       aws.Bool(true),\n        S3ForcePathStyle: aws.Bool(true),\n    })\n    if err != nil {\n        checkErr(err)\n    }\n\n    quit = make(chan int64)\n    cnt := 0\n    for rows.Next() {\n        var id int\n        var video_s3_url string\n        err = rows.Scan(&id, &video_s3_url)\n        checkErr(err)\n        go process(id, video_s3_url, bucket, end_point)\n\n        if cnt % 100 == 0 {\n            for i := cnt; i > 0; i-- {\n                <- quit\n            }\n        }\n        cnt++\n    }\n    //log.Println(cnt)\n    for i := cnt; i > 0; i-- {\n        <- quit\n    }\n}\n\nfunc process(id int, video_s3_url string, bucket string, end_point string) int64 {\n    fullpath := video_s3_url\n    fileSuffix := path.Ext(fileName)\n    fileSingleName := strings.TrimSuffix(fileName, fileSuffix)\n    output := fileSingleName + \".png\" \n    log.Println(output)\n\n    //delete exist file\n    //_ = os.Remove(output);\n    //if err != nil {\n    //    log.Println(err)\n    //}\n\n    log.Println(\"ffmpeg\", \"-i\", fullpath, \"-vframes\", \"1\", \"-ss\", \"3\", \"-t\", \"1\", output)\n    cmd := exec.Command(\"ffmpeg\", \"-i\", fullpath, \"-vframes\", \"1\", \"-ss\", \"3\", \"-t\", \"1\", output)\n    var buffer bytes.Buffer\n    cmd.Stdout = &buffer\n    if cmd.Run() != nil {\n        //panic(\"could not generate frame\")\n        log.Println(\"could not generate frame\")\n    }\n\n    // Upload\n    err := AddFileToS3(bucket, output)\n    if err != nil {\n        log.Println(\"could not update to s3\")\n        checkErr(err)\n    }\n    log.Println(output, \"update to s3\")\n\n    thumb_url := end_point + \"/\" + bucket + \"/\" + output\n\n    //update db\n    timeStr := time.Now().Format(\"2006-01-02 15:04:05\")\n    log.Println(\"update material_video set video_thumb_url='\", thumb_url, \"', update_time='\", timeStr, \"' where id=\", id)\n    stmt, err := db.Prepare(\"update material_video set video_thumb_url=?, update_time=? where id=?\")\n    defer stmt.Close()\n    checkErr(err)\n    res, err := stmt.Exec(thumb_url, timeStr, id)\n    //log.Println(\"res\", res)\n    checkErr(err)\n    affect, err := res.RowsAffected()\n    checkErr(err)\n    _ = os.Remove(output);\n    quit <- affect\n    return affect\n}\n\nfunc checkErr(err error) {\n    if err != nil {\n        log.Println(err)\n        panic(err)\n    }\n}\n\nfunc AddFileToS3(bucket string, fileDir string) error {\n\n    // Open the file for use\n    file, err := os.Open(fileDir)\n    if err != nil {\n        log.Println(err)\n        return err\n    }\n    defer file.Close()\n\n    // Get file size and read the file content into a buffer\n    fileInfo, _ := file.Stat()\n    var size int64 = fileInfo.Size()\n    buffer := make([]byte, size)\n    file.Read(buffer)\n\n    // Config settings: this is where you choose the bucket, filename, content-type etc.\n    // of the file you're uploading.\n    _, err = s3.New(s).PutObject(&s3.PutObjectInput{\n        Bucket:               aws.String(bucket),\n        Key:                  aws.String(fileDir),\n        //ACL:                  aws.String(\"private\"),\n        Body:                 bytes.NewReader(buffer),\n        ContentLength:        aws.Int64(size),\n        ContentType:          aws.String(http.DetectContentType(buffer)),\n        ContentDisposition:   aws.String(\"attachment\"),\n        ServerSideEncryption: aws.String(\"AES256\"),\n    })\n    return err\n}\n\ntype Config struct {\n    Db DBConfigInfo\n    S3 S3ConfigInfo\n}\n\ntype DBConfigInfo struct {\n    Dialect  string `yaml:\"dialect\"`\n    User     string `yaml:\"user\"`\n    Password string `yaml:\"password\"`\n    Host     string `yaml:\"host\"`\n    Port     string `yaml:\"port\"`\n    Database string `yaml:\"database\"`\n    Charset  string `yaml:\"charset\"`\n}\n\ntype S3ConfigInfo struct {\n    AccessKey     string `yaml:\"access_key\"`\n    SecretKey     string `yaml:\"secret_key\"`\n    EndPoint      string `yaml:\"end_point\"`\n    Bucket        string `yaml:\"bucket\"`\n}\n```\n**此处，对于新手需要注意：**\n\n在启动协程后，实际处理过程类似于在主线程中fork出子线程，由子线程完成实际的任务处理，但是，如果主线程没有等待协程处理完返回，特别是循环启动大批量协程的场景，则可能出现不是所有协程都被启动，或者协程处理没有正常返回等问题；\n对于这种情况，golang中提供了四种方式实现goroutine与主线程同步\n1. time.sleep()，这种方式较死板，不建议使用\n2. 使用channel机制，每个goroutine传一个channel进去然后往里写数据，在再主线程中读取这些channel，直到全部读到数据了子goroutine也就全部运行完了，那么主goroutine也就可以结束了。这种模式是子线程去通知主线程结束。\n3. 使用context中cancel函数，这种模式是主线程去通知子线程结束。\n4. sync.WaitGroup模式，Add方法设置等待子goroutine的数量，使用Done方法设置等待子goroutine的数量减1，当等待的数量等于0时，Wait函数返回。\n\n### 8 限制并发协程\n测试发现，使用goroutine并发，理论上可以快速处理批量任务，但是实际处理时，需要考虑数据库连接数及服务器CPU和内存等限制，考虑使用线程池的方式，限制同时处理任务的协程数\n```go\npackage main\n\nimport (\n    \"io/ioutil\"\n    yaml \"gopkg.in/yaml.v2\"\n    \"bytes\"\n    //\"fmt\"\n    \"log\"\n    \"path\"\n    \"path/filepath\"\n    \"strings\"\n    \"os\"\n    \"os/exec\"\n    \"database/sql\"\n    _ \"github.com/go-sql-driver/mysql\"\n    \"time\"\n\n    \"net/http\"\n    \"github.com/aws/aws-sdk-go/aws\"\n    \"github.com/aws/aws-sdk-go/aws/credentials\"\n    \"github.com/aws/aws-sdk-go/aws/session\"\n    \"github.com/aws/aws-sdk-go/service/s3\"\n\n    \"sync\"\n\n    \"github.com/panjf2000/ants\"\n)\n\nvar db *sql.DB\nvar s *session.Session\n\nfunc main() {\n    var (\n        Config Config\n        goSync sync.WaitGroup\n    )\n    data, err := ioutil.ReadFile(\"conf/conf.yaml\")\n    if err != nil {\n        checkErr(err)\n    }\n    err = yaml.Unmarshal(data, &Config)\n    if err != nil {\n        checkErr(err)\n    }\n\n    //user:password@tcp(localhost:5555)/dbname?charset=utf8\n    db, err = sql.Open(Config.Db.Dialect, Config.Db.User + \"@tcp(\" + Config.Db.Host + \":\" + Config.Db.Port + \")/\" + Config.Db.Database + \"?charset=\" + Config.Db.Charset)\n    checkErr(err)\n\n    //query date\n    rows, err := db.Query(\"SELECT id, video_s3_url FROM material_video where video_thumb_url is null\")\n    checkErr(err)\n\n    access_key := Config.S3.AccessKey\n    secret_key := Config.S3.SecretKey\n    end_point := Config.S3.EndPoint\n    bucket := Config.S3.Bucket\n    // Configure to use S3 Server\n    s, err = session.NewSession(&aws.Config{\n        Region: aws.String(\"us-west-2\"),\n        Credentials: credentials.NewStaticCredentials( access_key, secret_key, \"\"),  // token can be left blank for now\n        Endpoint:         aws.String(end_point),\n        DisableSSL:       aws.Bool(true),\n        S3ForcePathStyle: aws.Bool(true),\n    })\n    if err != nil {\n        checkErr(err)\n    }\n\n    defer ants.Release()\n    p, _ := ants.NewPoolWithFunc(Config.Pool.MaxNum, func(params interface{}) {\n        var id int\n        var video_s3_url string\n        for k, v := range params.(map[string]interface{}){\n            if k == \"id\" {\n                id = v.(int)\n            }\n            if k == \"video_s3_url\" {\n                video_s3_url = v.(string)\n            }\n        }\n        process(id, video_s3_url, bucket, end_point)\n        goSync.Done()\n    })\n    defer p.Release()\n    cnt := 0\n    for rows.Next() {\n        var id int\n        var video_s3_url string\n        err = rows.Scan(&id, &video_s3_url)\n        checkErr(err)\n\n        log.Println(id, video_s3_url, bucket, end_point)\n        params := make(map[string]interface{})\n        params[\"id\"] = id\n        params[\"video_s3_url\"] = video_s3_url\n\n        goSync.Add(1)\n        _ = p.Invoke(params)\n\n        cnt++\n    }\n    log.Println(cnt)\n\n    goSync.Wait()\n    //log.Printf(\"running goroutines: %d\\n\", ants.Running())\n    log.Printf(\"finish all tasks.\\n\")\n}\n\nfunc process(id int, video_s3_url string, bucket string, end_point string) int64 {\n    fullpath := video_s3_url\n    fileName := filepath.Base(fullpath)\n    fileSuffix := path.Ext(fileName)\n    fileSingleName := strings.TrimSuffix(fileName, fileSuffix)\n    output := fileSingleName + \".png\" \n    log.Println(output)\n\n    //delete exist file\n    //_ = os.Remove(output);\n    //if err != nil {\n    //    log.Println(err)\n    //}\n\n    log.Println(\"ffmpeg\", \"-i\", fullpath, \"-vframes\", \"1\", \"-ss\", \"3\", \"-t\", \"1\", output)\n    cmd := exec.Command(\"ffmpeg\", \"-i\", fullpath, \"-vframes\", \"1\", \"-ss\", \"3\", \"-t\", \"1\", output)\n    var buffer bytes.Buffer\n    cmd.Stdout = &buffer\n    if cmd.Run() != nil {\n        //panic(\"could not generate frame\")\n        log.Println(\"could not generate frame\")\n    }\n\n    // Upload\n    err := AddFileToS3(bucket, output)\n    if err != nil {\n        log.Println(\"could not update to s3\")\n        checkErr(err)\n    }\n    log.Println(output, \"update to s3\")\n\n    thumb_url := end_point + \"/\" + bucket + \"/\" + output\n\n    //update db\n    timeStr := time.Now().Format(\"2006-01-02 15:04:05\")\n    log.Println(\"update material_video set video_thumb_url='\", thumb_url, \"', update_time='\", timeStr, \"' where id=\", id)\n    stmt, err := db.Prepare(\"update material_video set video_thumb_url=?, update_time=? where id=?\")\n    defer stmt.Close()\n    checkErr(err)\n    res, err := stmt.Exec(thumb_url, timeStr, id)\n    checkErr(err)\n    affect, err := res.RowsAffected()\n    checkErr(err)\n    _ = os.Remove(output);\n    return affect\n}\n\nfunc checkErr(err error) {\n    if err != nil {\n        log.Println(err)\n        panic(err)\n    }\n}\n\nfunc AddFileToS3(bucket string, fileDir string) error {\n\n    // Open the file for use\n    file, err := os.Open(fileDir)\n    if err != nil {\n        log.Println(err)\n        return err\n    }\n    defer file.Close()\n\n    // Get file size and read the file content into a buffer\n    fileInfo, _ := file.Stat()\n    var size int64 = fileInfo.Size()\n    buffer := make([]byte, size)\n    file.Read(buffer)\n\n    // Config settings: this is where you choose the bucket, filename, content-type etc.\n    // of the file you're uploading.\n    _, err = s3.New(s).PutObject(&s3.PutObjectInput{\n        Bucket:               aws.String(bucket),\n        Key:                  aws.String(fileDir),\n        //ACL:                  aws.String(\"private\"),\n        Body:                 bytes.NewReader(buffer),\n        ContentLength:        aws.Int64(size),\n        ContentType:          aws.String(http.DetectContentType(buffer)),\n        ContentDisposition:   aws.String(\"attachment\"),\n        ServerSideEncryption: aws.String(\"AES256\"),\n    })\n    return err\n}\n\ntype Config struct {\n    Db   DBConfigInfo\n    S3   S3ConfigInfo\n    Pool GoroutinePoolInfo\n}\n\ntype DBConfigInfo struct {\n    Dialect  string `yaml:\"dialect\"`\n    User     string `yaml:\"user\"`\n    Password string `yaml:\"password\"`\n    Host     string `yaml:\"host\"`\n    Port     string `yaml:\"port\"`\n    Database string `yaml:\"database\"`\n    Charset  string `yaml:\"charset\"`\n}\n\ntype S3ConfigInfo struct {\n    AccessKey     string `yaml:\"access_key\"`\n    SecretKey     string `yaml:\"secret_key\"`\n    EndPoint      string `yaml:\"end_point\"`\n    Bucket        string `yaml:\"bucket\"`\n}\n\ntype GoroutinePoolInfo struct {\n    MaxNum string `yaml:\"max_num\"`\n}\n```\n\n### 参考\nhttps://stackoverflow.com/questions/35411585/first-frame-of-video\nhttps://github.com/astaxie/build-web-application-with-golang/blob/master/zh/05.2.md\nhttp://www.hatlonely.com/2018/03/04/golang-aws-sdk-go-%E4%B9%8B-s3-%E6%9C%8D%E5%8A%A1/index.html\nhttps://mlog.club/article/293940\nhttps://colobu.com/2016/12/21/how-to-dump-goroutine-stack-traces/\nhttps://mp.weixin.qq.com/s/aoWQSxrXXZUtJh48tmqMkA\nhttps://www.cnblogs.com/node-js/p/8964171.html\nhttps://www.cnblogs.com/williamjie/p/9267741.html\nhttps://github.com/panjf2000/ants"},{"title":"windows程序员常见乱码问题汇总","url":"/2019/08/18/gibberish/","content":"\n\n| 名称| 示例 | 特点 | 产生原因 |\n|---|---|---|---|\n| 古文码 | 鍝堝搱鐪嬪埌瀹堕噷鐫″ぇ瑙� | 大都为不认识的古文，夹杂日韩文 | 以GBK方式读取UTF-8编码的中文 |\n| 口子码 | ����������� | 大部分字符为小方块 | 以UTF-8方式读取GBK编码的中文 |\n| 符号码 | å“ˆå“ˆçœ‹åˆ°å®¶é‡Œç¡å¤§è§‰ | 大部分字符为各种符号 | 以ISO8859-1方式读取UTF-8编码的中文 |\n| 拼音码 | ¿¨·É»úÉÏµÄ | 大部分字符为头顶带各种类似声调符号的字母 | 以ISO8859-1方式读取GBK编码的中文 |\n| 问句码 | 幽月要好好学习天天向?? | 字符串长度为偶数时正常，长度为奇数时最后几个字符变为问号 | 以GBK的方式读取UTF-8编码的中文，然后用UTF-8格式再次读取 |\n| 锟拷码 | 锟斤拷锟斤拷锟斤拷锟 | 全中文字符，且大部分文字为“锟斤拷”几个字符 | 以UTF-8方式读取GBK编码的中文，然后用GBK格式再次读取 |"},{"title":"vue-router+nginx 路径配置方法","url":"/2019/08/11/vue-route-nginx/","content":"\nvue-router 的默认数据hash模式-使用url的hash来模拟一个完整的URL，于是当URL改变时，页面不会重新加载。\n\n \n\n一般情况下，我们不喜欢丑丑的hash，类似于index.html#/matchResult，可以使用路由的history模式。history模式是利用history.pushState API来实现页面跳转。\n\n \n\n但是有个问题，在使用nginx的时候，我们需要添加一些配置。\n\n \n\n## 直接配置在根路径下\n\n \n\n直接配置在根路径下，访问的时候只用输入[http://yoursite.com](http://yoursite.com/)，在nginx的配置如下\n\n \n\n```\n\nlocation / {\n\n  try_files $uri $uri/ /index.html;\n\n}\n\n```\n\n \n\n## 非根路径配置\n\n \n\n如果一个域名下有多个项目，那么使用根路径配置就不合适了，我们需要在根路径下指定一层路径，比如说\n\n \n\nA项目\n\n \n\n```\n\nhttp://yoursite.com/A\n\n```\n\n \n\nB项目\n\n \n\n```\n\nhttp://yoursite.com/B\n\n```\n\n \n\nnginx的配置\n\n \n\n```\n\n    location ^~/A {\n\n            alias /XX/A;//此处为A的路径\n\n            index index.html;\n\n            try_files $uri $uri/ /A/index.html;\n\n    }\n\n    location ^~/B {\n\n            alias /XX/B;//此处为B的路径\n\n            index index.html;\n\n            try_files $uri $uri/ /B/index.html;\n\n    }\n\n \n\n```\n\n \n\n**tip: 注意要用alias不能用root**\n\n"},{"title":"HTTP基础知识","url":"/2019/08/03/http-101/","content":"\n了解HTTP基础知识，对日常工作中web开发和问题排查有很大的帮助，在没有一定的项目经验之前学习这些基础知识会有一些困扰，但有过一定开发经验，尤其是遇到问题碰过几次壁之后再回来学习这些相关内容就会有不一样的感受了\n## 1. URI和URL\n这里我们先了解一下URI和URL，URI的全称为Uniform Resource Identifier，即统一资源标志符，URL的全称为Universal Resource Locator，即统一资源定位符。\n\n举例来说，[github.com/favicon.ico](https://github.com/favicon.ico)是GitHub的网站图标链接，它是一个URL，也是一个URI。即有这样的一个图标资源，我们用URL/URI来唯一指定了它的访问方式，这其中包括了访问协议https、访问路径（/即根目录）和资源名称favicon.ico。通过这样一个链接，我们便可以从互联网上找到这个资源，这就是URL/URI。\n\nURL是URI的子集，也就是说每个URL都是URI，但不是每个URI都是URL。那么，怎样的URI不是URL呢？URI还包括一个子类叫作URN，它的全称为Universal Resource Name，即统一资源名称。URN只命名资源而不指定如何定位资源，比如urn:isbn:0451450523指定了一本书的ISBN，可以唯一标识这本书，但是没有指定到哪里定位这本书，这就是URN。\n\n但在目前互联网中，几乎所有的URI都是URL，长久以后，我们一般都把网页链接统称为URL。\n\n## 2. URL完整格式\n在平常对前端同学的面试中，我都会让面试者解释他们对URL的了解，很多人都只能简单的说域名和请求路径两部分，但这明显是不完整的，也正因为对URL格式理解的不完整，导致在遇到一些特殊格式链接地址时手足无措。\n\n一个完整的URL链接格式\n```\nscheme://[username[:password]@]hostname[:port]/path/[;parameter]/[?query][#fragment]\n```\n各部分说明如下，其中括号部分为可选项\n\n|  字段|名 称| 说明 |\n|--------|--------|------|\n| scheme | 协议 |该链接地址使用的协议，常用的协议是http和https，其他ftp, file, nfs, sftp 等也都是合法的协议  |\n| :// | 分隔符 | 以此符号分隔协议和其他部分     |\n|hostname| 主机名 | 指明链接所在服务器的地址，可以是域名或IP地址     |\n|hort|端口| 提供服务的端口，针对不同协议有默认端口，如http对应80端口，https对应443端口，也可以自定义     |\n|path|路径|网络资源在服务器中的指定路径      |\n| ;parameter|参数| 可用于向服务器传入请求参数，用键值对表示，现在比较少见这种传递参数方式 |\n| ?query | 查询         | 用?将url的路径部分和其他部分区分开，大多服务端框架也习惯将get参数拼做query方式传递；注意：由于可能有异常导致出现多个问号，服务端会做一定的容错处理，截取后一段query的情况比较常见     |\n|#fragment|片段         |一小片或者一部分资源的名字。引用对象时，不会将frag字段传送给服务器。这个字段是在客户端内部使用的。通过字符”#”将其与URL的其余部分分隔开来。静态页面通常用片段配合锚点直接定位到页面的某个部分|\n|username[:password]@| 用户名密码        | 有一些服务（ftp）需要提供用户名密码验证，可以采用这种方式     |\n\n\n## 3. HTTP和HTTPS\nHTTP全称是Hyper Text Transfer Protocol，用于从网络传输超文本数据到本地浏览器的传送协议，目前广泛使用的是HTTP 1.1版本\n\nHTTPS的全称是Hyper Text Transfer Protocol over Secure Socket Layer，是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，简称为HTTPS。\n\nHTTPS的安全基础是SSL，主要作用是通过建立一个信息安全通道来保证数据传输安全，并且可以通过安全证书保证网站的真实性；HTTPS是未来发展的方向，越来越多的网站都要求将HTTPS作为标准服务。\n\n## 4. HTTP请求过程\n我们在浏览器中输入一个URL，回车之后便会在浏览器中观察到页面内容。实际上，这个过程是浏览器向网站所在的服务器发送了一个请求，网站服务器接收到这个请求后进行处理和解析，然后返回对应的响应，接着传回给浏览器。响应里包含了页面的源代码等内容，浏览器再对其进行解析，便将网页呈现了出来。\n\n为了更直观地地说明这个过程，这里用Chrome浏览器的开发者模式下的Network监听组件来做下演示，它可以显示访问当前请求网页时发生的所有网络请求和响应。\n\n打开Chrome浏览器，右击并选择“检查”项，即可打开浏览器的开发者工具。这里访问百度[www.github.com/](https://www.github.com)，输入该URL后回车，观察这个过程中发生了怎样的网络请求。可以看到，在Network页面下方出现了一个个的条目，其中一个条目就代表一次发送请求和接收响应的过程，如图所示\n\n![github_net](./resource/github_net.png)\n\n我们先观察网络请求，其中各列的含义如下。\n\n*   **第一列Name**：请求的名称，一般会将URL的最后一部分内容当作名称。\n*   **第二列Status**：响应的状态码，这里显示为307，代表临时重定向。通过状态码，我们可以判断发送了请求之后是否得到了正常的响应。\n*   **第三列Type**：请求的文档类型。这里为document，代表我们这次请求的是一个HTML文档，内容就是一些HTML代码。\n*   **第四列Initiator**：请求源。用来标记请求是由哪个对象或进程发起的。\n*   **第五列Size**：从服务器下载的文件和请求的资源大小。如果是从缓存中取得的资源，则该列会显示from cache。\n*   **第六列Time**：发起请求到获取响应所用的总时间。\n*   **第七列Waterfall**：网络请求的可视化瀑布流。\n\n点击这个条目，即可看到更详细的信息\n首先是General部分，Request URL为请求的URL，Request Method为请求的方法，Status Code为响应状态码，Remote Address为远程服务器的地址和端口，Referrer Policy为Referrer判别策略。\n\n再继续往下看，可以看到，有Response Headers和Request Headers，这分别代表响应头和请求头。请求头里带有许多请求信息，例如浏览器标识、Cookies、Host等信息，这是请求的一部分，服务器会根据请求头内的信息判断请求是否合法，进而作出对应的响应。图中看到的Response Headers就是响应的一部分，例如其中包含了服务器的类型、文档类型、日期等信息，浏览器接受到响应后，会解析响应内容，进而呈现网页内容。\n\n下面我们分别来介绍一下请求和响应都包含哪些内容。\n\n## 5. 请求\n请求，由客户端向服务端发出，可以分为4部分内容：请求方法（Request Method）、请求的网址（Request URL）、请求头（Request Headers）、请求体（Request Body）。\n\n### 5.1 请求方法\n常见的请求方法有GET和POST，GET和POST请求方法有如下区别。\n\n*   GET请求中的参数包含在URL里面，数据可以在URL中看到，而POST请求的URL不会包含这些数据，数据都是通过表单形式传输的，会包含在请求体中。\n*   GET请求提交的数据最多只有1024字节，而POST方式没有限制。\n\n一般来说，登录时，需要提交用户名和密码，其中包含了敏感信息，使用GET方式请求的话，密码就会暴露在URL里面，造成密码泄露，所以这里最好以POST方式发送。上传文件时，由于文件内容比较大，也会选用POST方式。\n\n我们平常遇到的绝大部分请求都是GET或POST请求，另外还有一些请求方法，如GET、HEAD、POST、PUT、DELETE、OPTIONS、CONNECT、TRACE等，我们简单将其总结为下表\n\n| 方法       | 描述 |\n| --------- | -------- |\n|GET |请求页面，并返回页面内容|\n|HEAD|类似于GET请求，只不过返回的响应中没有具体的内容，用于获取报头|\n|POST|大多用于提交表单或上传文件，数据包含在请求体中|\n|PUT|从客户端向服务器传送的数据取代指定文档中的内容|\n|DELETE|请求服务器删除指定的页面|\n|CONNECT|把服务器当作跳板，让服务器代替客户端访问其他网页|\n|OPTIONS|允许客户端查看服务器的性能|\n|TRACE|回显服务器收到的请求，主要用于测试或诊断|\n\n### 5.2 请求网址\n请求的网址，即统一资源定位符URL，它可以唯一确定我们想请求的资源。\n\n### 5.3 请求头\n请求头，用来说明服务器要使用的附加信息，比较重要的信息有Cookie、Referer、User-Agent等。下面简要说明一些常用的头信息。\n\n*   **Accept**：请求报头域，用于指定客户端可接受哪些类型的信息。\n*   **Accept-Language**：指定客户端可接受的语言类型。\n*   **Accept-Encoding**：指定客户端可接受的内容编码。\n*   **Host**：用于指定请求资源的主机IP和端口号，其内容为请求URL的原始服务器或网关的位置。从HTTP 1.1版本开始，请求必须包含此内容。\n*   **Cookie**：也常用复数形式 Cookies，这是网站为了辨别用户进行会话跟踪而存储在用户本地的数据。它的主要功能是维持当前访问会话。例如，我们输入用户名和密码成功登录某个网站后，服务器会用会话保存登录状态信息，后面我们每次刷新或请求该站点的其他页面时，会发现都是登录状态，这就是Cookies的功劳。Cookies里有信息标识了我们所对应的服务器的会话，每次浏览器在请求该站点的页面时，都会在请求头中加上Cookies并将其发送给服务器，服务器通过Cookies识别出是我们自己，并且查出当前状态是登录状态，所以返回结果就是登录之后才能看到的网页内容。\n*   **Referer**：此内容用来标识这个请求是从哪个页面发过来的，服务器可以拿到这一信息并做相应的处理，如作来源统计、防盗链处理等。\n*   **User-Agent**：简称UA，它是一个特殊的字符串头，可以使服务器识别客户使用的操作系统及版本、浏览器及版本等信息。在做爬虫时加上此信息，可以伪装为浏览器；如果不加，很可能会被识别出为爬虫。\n*   **Content-Type**：也叫互联网媒体类型（Internet Media Type）或者MIME类型，在HTTP协议消息头中，它用来表示具体请求中的媒体类型信息。例如，text/html代表HTML格式，image/gif代表GIF图片，application/json代表JSON类型，更多对应关系可以查看此对照表：[tool.oschina.net/commons](https://tool.oschina.net/commons)。\n\n### 5.4 请求体\n请求体一般承载的内容是POST请求中的表单数据，而对于GET请求，请求体则为空。需要注意Request Headers中指定Content-Type和POST内容的关系\n\n| Content-Type       | 提交数据的方式 |\n| --------- | -------- |\n|application/x-www-form-urlencoded|表单数据|\n|multipart/form-data|文件上传|\n|application/json|序列化json数据|\n|text/xml|xml数据|\n\n## 6. 响应\n响应，由服务端返回给客户端，可以分为三部分：响应状态码（Response Status Code）、响应头（Response Headers）和响应体（Response Body）。\n### 6.1 响应状态码\nhttp响应状态码表示服务器的响应状态，2XX表示服务正常，3XX一般为重定向，4XX一般为客户端请求异常，5XX为服务端异常\n常见的错误代码及错误原因\n\n|状态码| 说明|详情|\n|------|-----|-----|\n|100|继续|请求者应当继续提出请求。服务器已收到请求的一部分，正在等待其余部分|\n|101|切换协议|请求者已要求服务器切换协议，服务器已确认并准备切换|\n|200|成功|服务器已成功处理了请求|\n|201|创建成功|请求成功并且服务器创建了新的资源|\n|202|已接收|服务器已接受请求，但尚未处理|\n|203|非授权信息|服务器已成功处理了请求，但返回的信息可能来自另一个源|\n|204|无内容|服务器成功处理了请求，但没有返回任何内容|\n|205|重置内容|服务器成功处理了请求，内容被重置|\n|206|部分内容|服务器成功处理了部分请求|\n|300|多种选择|针对请求，服务器可执行多种操作|\n|301|永久移动|请求的网页已永久移动到新位置，即永久重定向|\n|302|临时移动|请求的网页暂时跳转到其他页面，即暂时重定向|\n|303|查看其他位置|如果原来的请求是POST，重定向目标文档应该通过GET提取|\n|304|未修改|此次请求返回的网页未修改，继续使用上次的资源|\n|305|使用代理|请求者应该使用代理访问该网页|\n|307|临时重定向|请求的资源临时从其他位置响应|\n|400|错误请求|服务器无法解析该请求，如用http请求一个https服务|\n|401|未授权|请求没有进行身份验证或验证未通过|\n|403|禁止范围|服务器拒绝此请求|\n|404|未找到|服务器找不到请求的网页|\n|405|方法禁用|服务器禁用了请求中指定的方法，如用GET请求一个只能用POST访问的地址|\n|406|不接受|无法使用请求的内容响应请求的网页|\n|407|需要代理授权|请求者需要使用代理授权|\n|408|请求超时|服务器请求超时|\n|409|冲突|服务器在完成请求时发生冲突|\n|410|已删除|请求的资源已永久删除|\n|411|需要有效长度|服务器不接受不含有效内容长度标头字段的请求|\n|412|未满足前提条件|服务器未满足请求者在请求中设置的其中一个前提条件|\n|413|请求实体过大|请求实体过大，超出服务器的处理能力|\n|414|请求URI过大|请求网址过长，服务器无法处理|\n|415|不支持类型|请求格式不被请求页面支持|\n|416|请求范围不符|页面无法提供请求的范围|\n|417|未满足期望值|服务器未满足期望请求标头字段的要求|\n|500|服务器内部错误|服务器遇到错误，无法完成请求|\n|501|未实现|服务器不具备完成请求的功能|\n|502|错误网关|服务器作为网关或代理，从上游服务器收到无效响应     |\n|503|服务不可用|服务器目前无法使用，因为请求超出负载导致服务临时不可用，可能在短时间内恢复|\n|504|网关超时|服务器作为网关或代理，但是没有及时从上游服务器收到请求|\n|505|http版本不支持|服务器不支持请求中所用的HTTP协议版本|\n更多内容参考 http://tool.oschina.net/commons?type=5\n\n### 5.2 响应头\n\n响应头包含了服务器对请求的应答信息，如Content-Type、Server、Set-Cookie等。下面简要说明一些常用的头信息。\n\n*   **Date**：标识响应产生的时间。\n*   **Last-Modified**：指定资源的最后修改时间。\n*   **Content-Encoding**：指定响应内容的编码。\n*   **Server**：包含服务器的信息，比如名称、版本号等。\n*   **Content-Type**：文档类型，指定返回的数据类型是什么，如text/html代表返回HTML文档，application/x-javascript则代表返回JavaScript文件，image/jpeg则代表返回图片。\n*   **Set-Cookie**：设置Cookies。响应头中的Set-Cookie告诉浏览器需要将此内容放在Cookies中，下次请求携带Cookies请求。\n*   **Expires**：指定响应的过期时间，可以使代理服务器或浏览器将加载的内容更新到缓存中。如果再次访问时，就可以直接从缓存中加载，降低服务器负载，缩短加载时间。\n\n### 5.3 响应体\n\n最重要的当属响应体的内容了。响应的正文数据都在响应体中，比如请求网页时，它的响应体就是网页的HTML代码；请求一张图片时，它的响应体就是图片的二进制数据。"},{"title":"Git 多平台换行符问题(LF or CRLF)","url":"/2019/04/24/git-lf-crlf/","content":"\n```bash\n$ git add .\nfatal: CRLF would be replaced by LF ...\n```\n![](https://wx1.sinaimg.cn/mw690/c3c88275ly1fdsav3d6yjj20hs0d5afx.jpg)\n\n**文本文件所使用的换行符，在不同的系统平台上是不一样的**。UNIX/Linux 使用的是 `0x0A（LF）`，早期的 Mac OS 使用的是 `0x0D（CR）`，后来的 OS X 在更换内核后与 UNIX 保持一致了。但 DOS/Windows 一直使用 `0x0D0A（CRLF）` 作为换行符。\n\n跨平台协作开发是常有的，不统一的换行符确实对跨平台的文件交换带来了麻烦。最大的问题是，在不同平台上，换行符发生改变时，Git 会认为整个文件被修改，这就造成我们没法 `diff`，不能正确反映本次的修改。还好 Git 在设计时就考虑了这一点，其提供了一个 `autocrlf` 的配置项，用于在提交和检出时自动转换换行符，该配置有三个可选项：\n\n*   **true:** 提交时转换为 LF，检出时转换为 CRLF\n*   **false:** 提交检出均不转换\n*   **input:** 提交时转换为LF，检出时不转换\n\n用如下命令即可完成配置：\n\n```\n# 提交时转换为LF，检出时转换为CRLF\ngit config --global core.autocrlf true\n\n# 提交时转换为LF，检出时不转换\ngit config --global core.autocrlf input\n\n# 提交检出均不转换\ngit config --global core.autocrlf false\n\n```\n\n如果把 autocrlf 设置为 false 时，那另一个配置项 `safecrlf` 最好设置为 **ture**。该选项用于检查文件是否包含混合换行符，其有三个可选项：\n\n*   **true:** 拒绝提交包含混合换行符的文件\n*   **false:** 允许提交包含混合换行符的文件\n*   **warn:** 提交包含混合换行符的文件时给出警告\n\n配置方法：\n\n```\n# 拒绝提交包含混合换行符的文件\ngit config --global core.safecrlf true\n\n# 允许提交包含混合换行符的文件\ngit config --global core.safecrlf false\n\n# 提交包含混合换行符的文件时给出警告\ngit config --global core.safecrlf warn\n\n```\n\n到此，还并未解决我遇到的问题。实际上，我们有两种办法解决。\n\n一种是将配置项改为如下的形式：\n\n```\n$ git config --global core.autocrlf false\n$ git config --global core.safecrlf false\n\n```\n\n这种方式是不推荐的，虽然代码能被提交，但是项目中的文件可能会包含两种格式的换行符。而且会有如上提到的问题，文件被视为整个被修改，无法 diff，之所以使用版本控制工具，最重要的原因之一就是其 diff 功能。\n\n另一种办法是，手动将文件的换行符转化为 LF，这可以通过编辑器来完成，大部分编辑器都可以将文件的换行符风格设置为 unix 的形式。也可以使用 `dos2unix` 转换工具来完成，Windows 上 Git bash 客户端自带了该工具。其他系统上也可以安装该工具，例如 Ubuntu 上安装：\n\n> sudo apt-get install dos2unix\n\n有了该工具，可以批量的把项目中的文件都转化一遍：\n\n> find . -type f | xargs dos2unix\n\n或者\n\n> find . -type f -exec dos2unix {} +\n\n如果涉及到在多个系统平台上工作，推荐将 git 做如下配置：\n\n```\n$ git config --global core.autocrlf input\n$ git config --global core.safecrlf true\n\n```\n\n也就是让代码仓库使用统一的换行符(LF)，如果代码中包含 CRLF 类型的文件时将无法提交，需要用 `dos2unix` 或者其他工具手动转换文件类型。当然，可以根据自己的需要进行更为合适的配置！\n\n## 防范\n\n首先，不要着急去整 Git，先整好自己。你的团队需要确立一个统一的换行符标准（推荐使用 UNIX 风格）。然后，团队的成员们需要分头做好准备工作——配置好自己的代码编辑器和 IDE，达到这两项要求：\n\n*   在新建文件时默认使用团队统一的换行符标准\n*   在打开文件时保持现有换行符格式不变（即不做自动转换）\n\n这样一方面可以最大程度保证项目代码的规范一致，另一方面，即使现有代码中遗留了一些不规范的情况，也不会因为反复转换而导致混乱。（当然，作为一个强迫症患者，我还是祝愿所有的项目从一开始就步入严谨有序的轨道。）\n\n接下来，我们就可以开始调教 Git 了。我的建议是， **完全关掉这个自作聪明的“换行符自动转换”功能**。关闭之后，Git 就不会对你的换行符做任何手脚了，你可以完全自主地、可预期地控制自己的换行符风格。\n\n下面主要针对不同的 Git 客户端，分别介绍一下操作方法。\n\n### Git for Windows\n\n这货由 Git 官方出品，在安装时就会向你兜售“换行符自动转换”功能，估计大多数人在看完华丽丽的功能介绍之后会毫不犹豫地选择第一项（自动转换）。请千万抵挡住诱惑，选择最后一项（不做任何手脚）。\n\n[![first-trap-on-github-autocrlf-git-install](https://camo.githubusercontent.com/c334a5644f69da294255a1de0a690239f8a83131/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313233313335392f3937343134392f64396564313662652d303634622d313165332d393336382d3831373138616563653335322e706e67)](https://camo.githubusercontent.com/c334a5644f69da294255a1de0a690239f8a83131/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313233313335392f3937343134392f64396564313662652d303634622d313165332d393336382d3831373138616563653335322e706e67)\n\n如果你已经做出了错误的选择，也不需要重新安装，可以直接使用命令行来修改设置。很简单，直接打开这货自带的命令行工具 Git Bash，输入以下命令，再敲回车即可：\n\n```source-shell\ngit config --global core.autocrlf false\n```\n\n[![first-trap-on-github-autocrlf-bash](https://camo.githubusercontent.com/47791095c618944f5838aa21b4cb6a7db5e6efb5/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313233313335392f3937343135342f66363163353066322d303634622d313165332d393530362d3366343238393066336331392e706e67)](https://camo.githubusercontent.com/47791095c618944f5838aa21b4cb6a7db5e6efb5/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313233313335392f3937343135342f66363163353066322d303634622d313165332d393530362d3366343238393066336331392e706e67)\n\n### TortoiseGit\n\n很多从 TortoiseSVN 走过来的同学很可能会选用 TortoiseGit 作为主力客户端，那么也需要配置一下。在 Windows 资源管理器窗口中点击右键，选择“TortoiseGit → Settings → Git”，做如下设置。\n\n[![first-trap-on-github-autocrlf-tortoisegit](https://camo.githubusercontent.com/8d6a7962aba0ce4e94ec32e4bf788360a84b301f/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313233313335392f3937343136322f31363930353264342d303634632d313165332d393434352d3535656637303238623633632e706e67)](https://camo.githubusercontent.com/8d6a7962aba0ce4e94ec32e4bf788360a84b301f/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313233313335392f3937343136322f31363930353264342d303634632d313165332d393434352d3535656637303238623633632e706e67)\n\n（由于 TortoiseGit 实际上是基于 Git for Windows 的一个 GUI 外壳，你在上一节所做的设置会影响到上图这些选项的状态，它们可能直接就是你所需要的样子了。）\n\n### GitHub 的 Windows 客户端\n\n它是今天的第二被告。这货很容易上手，很适合小白，我主要用它来一键克隆项目到本地。可能正是为了维护简洁易用的亲切形象，这货并没有像 TortoiseGit 那样提供丰富的选项（对“换行符自动转换”这样的细节功能完全讳莫如深啊，我这样的小白死了都不知道怎么死的……）。因此，我们需要手动修改一下它的配置。\n\nGitHub 的 Windows 客户端实际上也是一个壳，它自带了一个便携版的 Git for Windows。这个便携版和你自己安装的 Git for Windows 是相互独立的，不过它们都会使用同一个配置文件（实际上就是当前用户主目录下的 `.gitconfig` 文件）。\n\n所以如果你已经配置好了自己安装的 Git for Windows，那就不用操心什么了。但如果你的机器上只装过 GitHub 的 Windows 客户端，那么最简单的配置方法就是手工修改配置文件了。\n\n### 修改 Git 的全局配置文件\n\n进入当前用户的主目录（通常 XP 的用户目录是 `C:\\Documents and Settings\\yourname`，在 Vista 和 Win7 下是 `C:\\Users\\yourname`），用你最顺手的文本编辑器打开 `.gitconfig` 文件。\n\n在 `[core]` 区段找到 `autocrlf`，将它的值改为 `false`。如果没找到，就在 `[core]` 区段中新增一行：（最终效果见图）\n\n```source-ini\n    autocrlf = false\n```\n\n[![first-trap-on-github-autocrlf-gitconfig](https://camo.githubusercontent.com/6ffa4da0e063d96bd53efa07156b4322db46f483/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313233313335392f3937343136332f31666261353632302d303634632d313165332d396438612d6236653665653764333761322e706e67)](https://camo.githubusercontent.com/6ffa4da0e063d96bd53efa07156b4322db46f483/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313233313335392f3937343136332f31666261353632302d303634632d313165332d396438612d6236653665653764333761322e706e67)\n\n事实上上面介绍的所有命令行或图形界面的配置方法，最终效果都是一样的，因为本质上都是在修改这个配置文件。\n\n\n## **参考资料:**\n\n*   [https://toub.es/2012/05/28/fatal-crlf-would-be-replaced-lf](https://toub.es/2012/05/28/fatal-crlf-would-be-replaced-lf)\n*   [https://github.com/cssmagic/blog/issues/22](https://github.com/cssmagic/blog/issues/22)\n"},{"title":"windows环境下php-cgi使用curl请求接口阻塞超时的问题","url":"/2019/04/16/windows-php-cgi-timeout/","content":"# 问题\n\n在开发一个新功能，需要在运行的web界面，请求一个远程服务，功能很简单，用curl封转一个远程请求方法调用，对返回结果做简单处理即可；\n\n功能开发完成，为了测试，临时写了一个demo接口，在页面配置好该接口，结果测试请求时报错，追踪错误日志发现，在请求demo接口时超时未响应。\n\n# 分析\n\n首先通过浏览器访问，确认demo接口服务正常；在命令行中使用curl脚本也能获取正常返回结果；\n\n开发环境使用的是nginx虚拟主机+php-cgi部署，通过本地绑定host的方式访问，初步分析是php进程运行时不能获取系统host设置，于是准备采用在curl请求的header头中添加host的方式绑定域名；（后续回归发现，这个判断是不准确的，域名未绑定返回的错误信息是 Could not resolve host， 而实际返回的错误信息为 Operation timed out）\n\n在header头添加host设置之后，还是继续提示请求超时的错误，为确认代码无误，将发送远程请求的这段代码截取出来，测试代码如下：\n\n```php\n\n<?php\n$header = [\n  \"Host: demo.domain.com\",\n];\n\n$params = [];\n$ch = curl_init();\n$defaults[CURLOPT_URL] = 'http://127.0.0.1/api/demo';\n$defaults[CURLOPT_HEADER] = FALSE;\n$defaults[CURLOPT_USERAGENT] = \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.98 Safari/537.36\";\n$defaults[CURLOPT_FOLLOWLOCATION] = TRUE;\n$defaults[CURLOPT_RETURNTRANSFER] = TRUE;\n$defaults[CURLOPT_CONNECTTIMEOUT] = 3;\n$defaults[CURLOPT_TIMEOUT] = 3;\ncurl_setopt($ch, CURLOPT_HTTPHEADER, array('Expect:'));\n$options = [CURLOPT_HTTPHEADER=>$header];\ncurl_setopt_array($ch, (array) $options + $defaults);\n//var_dump($options, $defaults, (array) $options + $defaults);\n$data = curl_exec($ch);\ncurl_close($ch);\necho  $data;\n```\n\n在本地命令行执行代码，结果正常响应；通过比对各项请求参数配置，完全一致，说明功能代码应该是没有问题的，于是把注意力再放到环境上；\n\n经过一番搜索之后，大致定位到原因，**Windows下`PHP_FCGI_CHILDREN`无效**，也就是windows下默认本地只启了一个php-cgi进程，不会产生新进程去处理请求，有并发处理时只能排队，在用户访问一个php页面的时候nginx已将该进程占用，在该进程又发起http请求时，nginx发现这个仅有的进程已被占用而造成阻塞，就这样造成了死锁，一直到超时。\n\n# 方案\n\n## 使用linux环境\n\n- 方便快捷，杜绝一切后患，无需做任何修改\n\n## 在windows下启动额外的php-cgi处理并发请求\n\n- 直接在命令行启动新的php-cgi进程，监听不同端口，如：9001,9002,9003…\n\n```bash\nphp-cgi.exe -b 127.0.0.1:9001 -c php.ini\n```\n\n**注意保持命令行不被关闭**\n\n- 或者使用脚本（如 spawn-php.py）启动更多php-cgi进程127.0.0.1:[9001-9010]\n\n- 修改nginx配置，添加代理配置\n\n```bash\nupstream phpcgi_proxy {\n    server 127.0.0.1:9000,\n    server 127.0.0.1:9001,\n    server 127.0.0.1:9002,\n    #more\n}\n\n```\n\n并将配置替换为代理\n\n```bash\n#fastcgi_pass 127.0.0.1:9000;\nfastcgi_pass phpcgi_proxy\n```\n\n重新加载nginx配置生效\n\n# 后记\n\n在linux下，通过绑定系统host，或是在curl中设置header头host两种方法都能正常响应，完全不需要做这么多额外的处理，也不知道算不算浪费时间，-_-凸\n\n之前开发环境一直是在linux下，从来没有遇到过类似的问题，最近需要在windows下开发，时不时会遇到一些很诡异的问题。\n\n# 参考\n\n[https://stackoverflow.com/questions/13813667/php-curl-timing-out-but-cli-curl-works?rq=1](https://stackoverflow.com/questions/13813667/php-curl-timing-out-but-cli-curl-works?rq=1)\n\n[https://www.cnblogs.com/gudaojuanma/p/php-curl-nginx-timeout-cli-work.html](https://www.cnblogs.com/gudaojuanma/p/php-curl-nginx-timeout-cli-work.html)\n\n[https://www.mokeyjay.com/archives/1103](https://www.mokeyjay.com/archives/1103)\n","tags":["php"]},{"title":"协作开发的项目配置文件管理","url":"/2019/04/15/project-config-manage/","content":"# 背景\n我们在日常开发中经常遇到这样一些比较典型的情况：一个开发团队有多个成员，每个人各自使用不同的开发环境，linux、windows或者Mac OS，每个人使用的IDE也不尽相同。\n对于程序本身，并没有什么问题，php可以在各个平台正常运行，但是每个人可能会有各自的开发环境，团队应该提供单独的测试环境，线上服务也可能需要提供灰度和正式环境，不同的环境对应的配置文件中服务配置、数据库配置、路径配置多少都会有不一致的设置。\n以thinkphp为例，项目基本配置都在config.php和database.php中，为保证服务能正常启动运行，配置文件必不可缺，都应该提交到代码仓库中去（**注意：如果代码库是公开的github，则用户名密码等敏感信息一定不能提交发布**，本文所讨论情况，局限于私有代码库）\n这在代码的版本控制上，可能出现以下几种麻烦：\n- 成员在本地开发的时候，都需要将配置修改为各自不同的设置，提交代码和拉去代码时，可能产生冲突，虽然不难解决，但每次解决类似问题比较影响效率\n- 也有成员处于安全考虑，不将本地敏感配置提交到代码库，但每次拉取代码后，本地设置都需要重新修改一遍\n- 不同测试和生产环境使用的配置不同，每次发布上线代码时都需要认真比对修改配置，无法完全自动化处理\n- 可以简单粗暴的将配置文件排除在代码库之外，这能解决上面一部分问题，但是显然代码库是不完整的，新成员直接拉取代码是无法运行的，更致命的是，当项目需要新增或修改一个公共配置的时候，不得不通知所有成员手动更新配置文件\n- ……\n\n# 方案对比\n## 基于Base类的配置文件\n曾经在一些历史项目中采用这个方案，框架为基础极简架构，只提供基础mvc；在项目中使用一个Config类作为主配置文件，Config类继承自ConfigBase类，配置项都声明为类中的常量，在使用配置项的地方直接读取子类的常量参数；\n所有配置项都会在基类进行定义，环境有别于基类的配置则在子类中重新声明，覆盖基类定义，这样每个人都可以有自己的环境配置，且添加公共配置的时候，直接添加到ConfigBase就可以；\n项目初始化的时候，所有配置都写在基类中，Config类默认为空，后续开发过程中，可以将本地配置设置到Config类中，并将Config.php文件添加到代码库ignore配置中，这样就可以满足协同开发配置问题；\n如果希望将自己的配置文件也添加到代码库中进行变更管理，可以复制Config.php生成带个人后缀的配置文件Config.php.dev，将个人文件提交到代码库，之后重新生成链接文件Config.php指向到个人配置文件，即可满足要求；\n```php\nConfig.php\n<?php\nclass Config extends ConfigBase\n{\n    const LOG_PATH = '/home/user/log/project/';\n    ...\n}\n\nConfigBase.php\n<?php\nclass ConfigBase\n{\n    const LOG_PATH = '/var/log/project/';\n    ...\n}\n\nDemo.php\n<?php\nclass Demo\n{\n    public function test()\n    {\n        $logPath = Config::LOG_PATH;\n    }\n}\n```\n\n## 辅助脚本生成/更新配置文件\n对于一些目前比较流行的开源框架（以thinkphp为例），基本都是采用在指定路径的config.php文件中返回php数组的方式定义系统配置，（也支持.ini，.xml，.json等格式的配置文件，单最终也都由框架解析为php数组。）显然，前面所提到的方式不适用，但在这个方案的基础上我们可以做一点变化满足要求。\n框架默认读取的配置文件是config.php和database.php，还是以config配置为例，考虑添加config.base.php作为基础配置文件，包括全部配置项，再增加一个config.dev.php作为个人配置文件，默认返回空数组，有个人配置项时，个人配置覆盖基础配置；项目实际还是从config.php读取配置，初始化默认为空；\n编写一个脚手架脚本，提供初始化和更新功能，初始化时，根据config.base.php和config.dev.php配置生成一个合并的配置文件config.php供项目读取；执行更新任务时，比对config.php文件、基础配置和个人配置，如果基础配置有新增，则将新加配置项添加到config.php中，如果有配置修改，依照个人配置覆盖基础配置的原则将配置项更新到config.php文件中；\n同样，将config.php文件加到代码库ignore配置中，添加个人后缀的本地配置文件，并可提交到代码库管理，执行脚本时，指定自己使用的本地配置文件，同样可以满足协同开发的配置管理基本要求。\n\n## 基于环境变量的配置管理\nphp本身可以通过getenv获取环境变量，现在主流的框架对环境变量也有很好的支持，所以考虑通过设置环境变量的方式来指定加载不同的配置文件，这样就可以满足针对不同环境使用不同配置的管理和切换问题；\n\n### 常见设置环境变量方法：\n```\n#Apache\nSetEnv APPLICATION_ENV develop\n\n#nginx\nfastcgi_param APPLICATION_ENV develop;\n\n#php cli\n$ export APPLICATION_ENV=develop\n```\n\n那么框架就会自动加载对应的配置文件（默认位于 `application/develop.php`），根据配置加载优先级，该配置会覆盖默认的应用配置，应用配置文件是应用初始化的时候首先加载的公共配置文件，默认位于`application/config.php`。这样添加和修改公共配置的问题也解决了。\n现在，我们再来处理一个细节问题，将环境变量的值设置到框架配置，把前面的操作结合到一起就可以完成，处理如下\n1 在web服务环境中[设置环境变量](#常见设置环境变量方法：)\n2 在项目入口处读取所设置的环境变量，并定义为常量\n```php\n<?php\n...\n$env = isset($_SERVER['APPLICATION_ENV']) ? $_SERVER['APPLICATION_ENV'] : 'development';\ndefine('APP_STATUS', $env);\n...\n```\n3 把所定义的常量设置到配置文件config.php中\n```php\n'app_status' => APP_STATUS\n```\n通过以上几步，基本完成了通过设置环境变量指定配置文件的功能。\n\n## 使用 .env 设置环境变量\n前面的配置虽然实现了功能，但需要修改web服务器的配置添加额外配置，任何非标准配置都不利于系统的自动化运维，可能在部署过程中遗留导致服务部署异常，所以不一定是最好的方案；另外需要单独修改框架中非业务逻辑，好像也不是特别好；\n在分析thinkphp配置文件的过程中，注意到很多配置项使用的是Env::get()方式设置的，其实就是thinkphp5.0支持的环境变量配置，在开发过程中，可以在应用根目录下面的`.env`来模拟环境变量配置，`.env`文件中的配置参数定义格式采用`ini`方式，所有我们可以在这里设置app_status配置\n```\n[app]\nstatus = develop\n```\n并修改config.php配置文件\n```\n'app_status' => Env::get('app.status'),\n```\n同样满足了之前的一系列要求，只需要保证不把`.env`文件添加到代码库即可\n\n注意：如果部署环境单独配置了环境变量，需要删除`.env`配置文件，避免冲突。\n\n## 副产品\n使用`.env`设置环境变量还能解决敏感信息配置安全性的问题，如，数据库配置文件中，用户名密码字段的值可以直接留空，从环境变量文件中设置即可\n```\n.env\n\n[database]\nusername =  root\npassword =  123456\n\ndatabase.php\n// 用户名 \n'username' => Env::get('database.username', ''), \n// 密码 \n'password' => Env::get('database.password', ''),\n```\n\n\n# 小结\n除了上面列举的几种方法，还有很多不同的处理，没有哪种实现是完美的，个人觉得选择方案主要还是要从支持协作开发，便于开发维护，支持持续集成，兼顾安全等各方面权衡。并且不同团队的开发使用习惯也不尽相同，还是应该选择最适合团队项目的实现方式。\n\n#参考\n[环境和配置文件](http://www.digpage.com/environment.html)\n[thinkphp5.0完全开发手册-配置](https://www.kancloud.cn/manual/thinkphp5/118024)\n\n","tags":["php"]},{"title":"使用Hexo+github搭建博客（基础）","url":"/2019/04/13/first-Hexo/","content":"#  前提\n- 安装Node.js，配置node环境\n- 安装和配置git\n- 注册github账号，新建项目，项目名设定为：{username}.github.io，并且勾选Initialize this repository with a README\n\n#  安装Hexo\n新建文件夹\n```bash\nmkdir blog\ncd blog\n```\n安装Hexo\n```bash\nnpm install hexo -g\n```\n检查安装结果\n```bash\nhexo -v\n```\n初始化\n```bash\nhexo init\n```\n安装所有依赖组件\n```bash\nnpm install\n```\n生成blog网站代码\n```bash\nhexo g\n```\n启动本地服务\n```bash\nhexo s\n```\n如果启动成功，可访问http://localhost:4000 进行预览\n如果页面无法访问，可能是本地端口被占用，可使用以下命令更改端口启动服务\n```bash\nhexo server -p port\n```\n当出现如下界面表示服务启动成功\n![](https://images2017.cnblogs.com/blog/1108615/201710/1108615-20171021232413224-1288183746.png)\n\n# 将hexo与github page关联起来\n设置git的user和email\n```bash\ngit config --global user.name \"you name\"\ngit config --global user.email \"you email\"\n```\n设置git免密信任授权，将本地`~/.ssh/id_rsa.pub` 文件的内容添加到github settings->SSH keys\n测试ssh信任是否成功\n```bash\nssh -T git@github.com\n```\n配置Deployment，在文件夹中找到`_config.yml`配置文件，修改repo的值\n```yml\ndeploy:\n  type: git\n  repository: git@github.com:username/username.github.io.git\n  branch: master\n```\n新建一篇博客\n```bash\nhexo new post \"new.post.for.hexo\"\n```\n这时候在_posts目录下会看到新创建的文件（new-post-for-hexo.md）\n安装一个扩展，用于把新的文件部署到github\n```bash\nnpm install hexo-deployer-git --save\n```\n使用编辑器编写文章并保存\n执行命令生成并发布文章\n```bash\nhexo d -g\n```\n部署成功后，就可以访问github的地址，http://username.github.io ，即可看到新生成的文章\n* [ ] 至此，博客的基本搭建就完成了。想·\n\n","tags":["hexo"]},{"title":"Hello World","url":"/2019/04/13/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n"}]